% Generated by IEEEtran.bst, version: 1.14 (2015/08/26)
\begin{thebibliography}{10}
\providecommand{\url}[1]{#1}
\csname url@samestyle\endcsname
\providecommand{\newblock}{\relax}
\providecommand{\bibinfo}[2]{#2}
\providecommand{\BIBentrySTDinterwordspacing}{\spaceskip=0pt\relax}
\providecommand{\BIBentryALTinterwordstretchfactor}{4}
\providecommand{\BIBentryALTinterwordspacing}{\spaceskip=\fontdimen2\font plus
\BIBentryALTinterwordstretchfactor\fontdimen3\font minus
  \fontdimen4\font\relax}
\providecommand{\BIBforeignlanguage}[2]{{%
\expandafter\ifx\csname l@#1\endcsname\relax
\typeout{** WARNING: IEEEtran.bst: No hyphenation pattern has been}%
\typeout{** loaded for the language `#1'. Using the pattern for}%
\typeout{** the default language instead.}%
\else
\language=\csname l@#1\endcsname
\fi
#2}}
\providecommand{\BIBdecl}{\relax}
\BIBdecl

\bibitem{kanso2009automated}
K.~Kanso, F.~Moller, and A.~Setzer, ``Automated verification of signalling
  principles in railway interlocking systems,'' \emph{Electronic Notes in
  Theoretical Computer Science}, vol. 250, no.~2, pp. 19--31, 2009.

\bibitem{james2013verification}
P.~James, A.~Lawrence, F.~Moller, M.~Roggenbach, M.~Seisenberger, A.~Setzer,
  K.~Kanso, and S.~Chadwick, ``Verification of solid state interlocking
  programs,'' in \emph{International Conference on Software Engineering and
  Formal Methods}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2013, pp.
  253--268.

\bibitem{mnih2016asynchronous}
V.~Mnih, A.~P. Badia, M.~Mirza, A.~Graves, T.~P. Lillicrap, T.~Harley,
  D.~Silver, and K.~Kavukcuoglu, ``Asynchronous methods for deep reinforcement
  learning,'' 2016.

\bibitem{groote1995safety}
J.~F. Groote, S.~F. van Vlijmen, and J.~W. Koorn, ``The safety guaranteeing
  system at station hoorn-kersenboogerd,'' in \emph{COMPASS'95 Proceedings of
  the Tenth Annual Conference on Computer Assurance Systems Integrity, Software
  Safety and Process Security'}.\hskip 1em plus 0.5em minus 0.4em\relax IEEE,
  1995, pp. 57--68.

\bibitem{fokkink1998verification}
W.~Fokkink, P.~Hollingshead, J.~Groote, S.~Luttik, and J.~van Wamel,
  ``Verification of interlockings: from control tables to ladder logic
  diagrams,'' in \emph{Proceedings of FMICS}, vol.~98, 1998, pp. 171--185.

\bibitem{fantechi2012some}
A.~Fantechi, W.~Fokkink, and A.~Morzenti, ``Some trends in formal methods
  applications to railway signaling,'' \emph{Formal methods for industrial
  critical systems: A survey of applications}, pp. 61--84, 2012.

\bibitem{ferrari2011model}
A.~Ferrari, G.~Magnani, D.~Grasso, and A.~Fantechi, ``Model checking
  interlocking control tables,'' in \emph{FORMS/FORMAT 2010}.\hskip 1em plus
  0.5em minus 0.4em\relax Springer, 2011, pp. 107--115.

\bibitem{haxthausen2008modelling}
A.~E. Haxthausen, M.~L. Bliguet, and A.~A. Kj{\ae}r, ``Modelling and
  verification of relay interlocking systems,'' in \emph{Monterey
  Workshop}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 2008, pp.
  141--153.

\bibitem{1688959}
M.~Awedh and F.~Somenzi, ``Automatic invariant strengthening to prove
  properties in bounded model checking,'' in \emph{2006 43rd ACM/IEEE Design
  Automation Conference}, 2006, pp. 1073--1076.

\bibitem{case2007automated}
M.~L. Case, A.~Mishchenko, and R.~K. Brayton, ``Automated extraction of
  inductive invariants to aid model checking,'' in \emph{Formal Methods in
  Computer Aided Design (FMCAD'07)}.\hskip 1em plus 0.5em minus 0.4em\relax
  IEEE, 2007, pp. 165--172.

\bibitem{bensalem1996powerful}
S.~Bensalem, Y.~Lakhnech, and H.~Saidi, ``Powerful techniques for the automatic
  generation of invariants,'' in \emph{International Conference on Computer
  Aided Verification}.\hskip 1em plus 0.5em minus 0.4em\relax Springer, 1996,
  pp. 323--335.

\bibitem{garg2016learning}
P.~Garg, D.~Neider, P.~Madhusudan, and D.~Roth, ``Learning invariants using
  decision trees and implication counterexamples,'' \emph{ACM Sigplan Notices},
  vol.~51, no.~1, pp. 499--512, 2016.

\bibitem{sutton2018reinforcement}
R.~S. Sutton and A.~G. Barto, \emph{Reinforcement learning: An
  introduction}.\hskip 1em plus 0.5em minus 0.4em\relax MIT press, 2018.

\bibitem{schaul2015prioritized}
T.~Schaul, J.~Quan, I.~Antonoglou, and D.~Silver, ``Prioritized experience
  replay,'' \emph{arXiv preprint arXiv:1511.05952}, 2015.

\bibitem{silver2016mastering}
D.~Silver, A.~Huang, C.~J. Maddison, A.~Guez, L.~Sifre, G.~Van Den~Driessche,
  J.~Schrittwieser, I.~Antonoglou, V.~Panneershelvam, M.~Lanctot \emph{et~al.},
  ``Mastering the game of go with deep neural networks and tree search,''
  \emph{nature}, vol. 529, no. 7587, pp. 484--489, 2016.

\bibitem{vinyals2019grandmaster}
O.~Vinyals, I.~Babuschkin, W.~M. Czarnecki, M.~Mathieu, A.~Dudzik, J.~Chung,
  D.~H. Choi, R.~Powell, T.~Ewalds, P.~Georgiev \emph{et~al.}, ``Grandmaster
  level in starcraft ii using multi-agent reinforcement learning,''
  \emph{Nature}, vol. 575, no. 7782, pp. 350--354, 2019.

\bibitem{gu2017deep}
S.~Gu, E.~Holly, T.~Lillicrap, and S.~Levine, ``Deep reinforcement learning for
  robotic manipulation with asynchronous off-policy updates,'' in \emph{2017
  IEEE international conference on robotics and automation (ICRA)}.\hskip 1em
  plus 0.5em minus 0.4em\relax IEEE, 2017, pp. 3389--3396.

\bibitem{bloesch2022towards}
M.~Bloesch, J.~Humplik, V.~Patraucean, R.~Hafner, T.~Haarnoja, A.~Byravan,
  N.~Y. Siegel, S.~Tunyasuvunakool, F.~Casarini, N.~Batchelor \emph{et~al.},
  ``Towards real robot learning in the wild: A case study in bipedal
  locomotion,'' in \emph{Conference on Robot Learning}.\hskip 1em plus 0.5em
  minus 0.4em\relax PMLR, 2022, pp. 1502--1511.

\bibitem{mazyavkina2021reinforcement}
N.~Mazyavkina, S.~Sviridov, S.~Ivanov, and E.~Burnaev, ``Reinforcement learning
  for combinatorial optimization: A survey,'' \emph{Computers \& Operations
  Research}, vol. 134, p. 105400, 2021.

\bibitem{watkins1992q}
C.~J. Watkins and P.~Dayan, ``Q-learning,'' \emph{Machine learning}, vol.~8,
  no.~3, pp. 279--292, 1992.

\bibitem{lecun2015deep}
Y.~LeCun, Y.~Bengio, and G.~Hinton, ``Deep learning,'' \emph{nature}, vol. 521,
  no. 7553, pp. 436--444, 2015.

\bibitem{mnih2013playing}
V.~Mnih, K.~Kavukcuoglu, D.~Silver, A.~Graves, I.~Antonoglou, D.~Wierstra, and
  M.~Riedmiller, ``Playing atari with deep reinforcement learning,''
  \emph{arXiv preprint arXiv:1312.5602}, 2013.

\bibitem{kakade2001natural}
S.~M. Kakade, ``A natural policy gradient,'' \emph{Advances in neural
  information processing systems}, vol.~14, 2001.

\bibitem{schulman2017trust}
J.~Schulman, S.~Levine, P.~Moritz, M.~I. Jordan, and P.~Abbeel, ``Trust region
  policy optimization,'' 2017.

\bibitem{schulman2017proximal}
J.~Schulman, F.~Wolski, P.~Dhariwal, A.~Radford, and O.~Klimov, ``Proximal
  policy optimization algorithms,'' 2017.

\bibitem{gordillo2021improving}
C.~Gordillo, J.~Bergdahl, K.~Tollmar, and L.~Gissl{\'e}n, ``Improving
  playtesting coverage via curiosity driven reinforcement learning agents,''
  \emph{arXiv preprint arXiv:2103.13798}, 2021.

\bibitem{9231552}
J.~Bergdahl, C.~Gordillo, K.~Tollmar, and L.~Gissl√©n, ``Augmenting automated
  game testing with deep reinforcement learning,'' in \emph{2020 IEEE
  Conference on Games (CoG)}, 2020, pp. 600--603.

\bibitem{9678703}
Y.~Cao, Y.~Zheng, S.-W. Lin, Y.~Liu, Y.~S. Teo, Y.~Toh, and V.~V. Adiga,
  ``Automatic hmi structure exploration via curiosity-based reinforcement
  learning,'' in \emph{2021 36th IEEE/ACM International Conference on Automated
  Software Engineering (ASE)}, 2021, pp. 1151--1155.

\bibitem{9402046}
Y.~Zheng, Y.~Liu, X.~Xie, Y.~Liu, L.~Ma, J.~Hao, and Y.~Liu, ``Automatic web
  testing using curiosity-driven reinforcement learning,'' in \emph{2021
  IEEE/ACM 43rd International Conference on Software Engineering (ICSE)}, 2021,
  pp. 423--435.

\bibitem{9476756}
A.~Peake, J.~McCalmon, Y.~Zhang, D.~Myers, S.~Alqahtani, and P.~Pauca, ``Deep
  reinforcement learning for adaptive exploration of unknown environments,'' in
  \emph{2021 International Conference on Unmanned Aircraft Systems (ICUAS)},
  2021, pp. 265--274.

\bibitem{s21041067}
\BIBentryALTinterwordspacing
K.~G.~S. Apuroop, A.~V. Le, M.~R. Elara, and B.~J. Sheu, ``Reinforcement
  learning-based complete area coverage path planning for a modified htrihex
  robot,'' \emph{Sensors}, vol.~21, no.~4, 2021. [Online]. Available:
  \url{https://www.mdpi.com/1424-8220/21/4/1067}
\BIBentrySTDinterwordspacing

\bibitem{electronics10222751}
\BIBentryALTinterwordspacing
D.~I. Koutras, A.~C. Kapoutsis, A.~A. Amanatiadis, and E.~B. Kosmatopoulos,
  ``Marsexplorer: Exploration of unknown terrains via deep reinforcement
  learning and procedurally generated environments,'' \emph{Electronics},
  vol.~10, no.~22, 2021. [Online]. Available:
  \url{https://www.mdpi.com/2079-9292/10/22/2751}
\BIBentrySTDinterwordspacing

\bibitem{manchanda2019learning}
S.~Manchanda, A.~Mittal, A.~Dhawan, S.~Medya, S.~Ranu, and A.~Singh, ``Learning
  heuristics over large graphs via deep reinforcement learning,'' \emph{arXiv
  preprint arXiv:1903.03332}, 2019.

\bibitem{hoffman2020acme}
M.~Hoffman, B.~Shahriari, J.~Aslanides, G.~Barth-Maron, F.~Behbahani,
  T.~Norman, A.~Abdolmaleki, A.~Cassirer, F.~Yang, K.~Baumli \emph{et~al.},
  ``Acme: A research framework for distributed reinforcement learning,''
  \emph{arXiv preprint arXiv:2006.00979}, 2020.

\bibitem{ostrovski2017countbased}
G.~Ostrovski, M.~G. Bellemare, A.~van~den Oord, and R.~Munos, ``Count-based
  exploration with neural density models,'' 2017.

\bibitem{haarnoja2018soft}
T.~Haarnoja, A.~Zhou, P.~Abbeel, and S.~Levine, ``Soft actor-critic: Off-policy
  maximum entropy deep reinforcement learning with a stochastic actor,'' 2018.

\bibitem{wang2017sample}
Z.~Wang, V.~Bapst, N.~Heess, V.~Mnih, R.~Munos, K.~Kavukcuoglu, and
  N.~de~Freitas, ``Sample efficient actor-critic with experience replay,''
  2017.

\bibitem{houthooft2017vime}
R.~Houthooft, X.~Chen, Y.~Duan, J.~Schulman, F.~D. Turck, and P.~Abbeel,
  ``Vime: Variational information maximizing exploration,'' 2017.

\bibitem{espeholt2018impala}
L.~Espeholt, H.~Soyer, R.~Munos, K.~Simonyan, V.~Mnih, T.~Ward, Y.~Doron,
  V.~Firoiu, T.~Harley, I.~Dunning, S.~Legg, and K.~Kavukcuoglu, ``Impala:
  Scalable distributed deep-rl with importance weighted actor-learner
  architectures,'' 2018.

\end{thebibliography}
